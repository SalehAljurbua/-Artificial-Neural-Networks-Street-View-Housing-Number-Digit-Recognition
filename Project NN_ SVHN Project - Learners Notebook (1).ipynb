{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q91KqmCRu64D"
   },
   "source": [
    "# Project- Artificial Neural Networks: Street View Housing Number Digit Recognition\n",
    "\n",
    "**Marks: 30**\n",
    "\n",
    "\n",
    "\n",
    "Dear Learner,\n",
    "\n",
    "Welcome to project on Classification using Artificial Neural Networks. We will work with the Street View Housing Numbers image dataset for this project work.\n",
    "\n",
    "Do read the problem statement and the guidelines around the same.\n",
    "\n",
    "----\n",
    "### Context: \n",
    "-------\n",
    "\n",
    "The ability to process visual information using machine learning algorithms can be very useful as demonstrated in various applications. The Street View House Numbers (SVHN) dataset is one of the most popular ones. It has been used in neural networks created by Google to read house numbers and match them to their geolocations. This is a great benchmark dataset to play with, learn and train models that accurately identify street numbers, and incorporate into all sorts of projects.\n",
    "\n",
    "---------\n",
    "### Objective:\n",
    "------------\n",
    "The objective of the exercise is to perform an image classification exercise on the given dataset to come up with a model that can help identify the digit images which have issues like picture brightness, blurriness. \n",
    "\n",
    "--------\n",
    "### More about the dataset\n",
    "------------\n",
    "- The dataset is provided as a .h5 file. The basic preprocessing steps have been done.\n",
    "\n",
    "---------------------------\n",
    "### Guidelines\n",
    "-----------------------------------------\n",
    "- You need to download the dataset from the given link and add it to your drive. Use colab for this exercise. \n",
    "- You will need to mount the drive and give proper path to read the dataset.\n",
    "- The exercise consists of semi written code blocks. You need to fill the blocks as per the instructions to achieve the required results.\n",
    "- To be able to complete the assessment in the expected time, do not change the variable names. The codes might throw errors when the names are changed. \n",
    "- The marks of each requirement is mentioned in the question.\n",
    "- You can raise your issues on the discussion forum on the Olympus.\n",
    "- Uncomment the code snippets and work on them\n",
    "--------------------------------------------\n",
    "Wishing you all the best!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z2Z7-OAs8QG"
   },
   "source": [
    "### Mount the drive\n",
    "Let us start by mounting the drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1425,
     "status": "ok",
     "timestamp": 1606902300334,
     "user": {
      "displayName": "Shrish Chandra Pandey",
      "photoUrl": "",
      "userId": "03777729159992968707"
     },
     "user_tz": -330
    },
    "id": "REFUdThmpz_d",
    "outputId": "7df24ef4-6876-47ea-ce93-a411add882c5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucnevGLoyKf_"
   },
   "source": [
    "Let us check for the version of installed tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1606902303290,
     "user": {
      "displayName": "Shrish Chandra Pandey",
      "photoUrl": "",
      "userId": "03777729159992968707"
     },
     "user_tz": -330
    },
    "id": "W5as47YxyJVk",
    "outputId": "f040ecec-fcab-4131-913c-0a91f9ac493c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f83c6d50081b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lsux2ZwyTTR"
   },
   "source": [
    "### Load the dataset\n",
    "- Let us now, load the dataset that is available as a .h5 file.\n",
    "- Split the data into train and the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BApX9qgNsqV0",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/content/drive/My Drive/SVHN_single_grey1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4e7b2f9dd60e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Open the file as readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Make changes in path as required\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mh5f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/SVHN_single_grey1.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Load the training and the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/My Drive/SVHN_single_grey1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Open the file as readonly\n",
    "# Make changes in path as required\n",
    "h5f = h5py.File('/content/drive/My Drive/SVHN_single_grey1.h5', 'r')\n",
    "\n",
    "# Load the training and the test set\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train1 = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test1 = h5f['y_test'][:]\n",
    "\n",
    "\n",
    "# Close this file\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nX4VEpfIyeaW"
   },
   "source": [
    "Let us import the required libraries now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTeAO8HpsqV8"
   },
   "outputs": [],
   "source": [
    "## Importing the required libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxODV6HKykuc"
   },
   "source": [
    "### Visualising images (3 marks)\n",
    "- Use X_train to visualise the first 10 images. (2 marks)\n",
    "- Use Y_train to print the first 10 labels (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bvsc8ytHsqWD"
   },
   "outputs": [],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(__, __))\n",
    "# for i in range(__):\n",
    "#     plt.subplot(1, 10, i+1)\n",
    "#     plt.imshow(______, ___=\"gray\")\n",
    "#     plt.axis('off')\n",
    "# plt._____()\n",
    "# print('label for each of the above image: %s' % (y_train1[_:_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzoyeXHOy80N"
   },
   "source": [
    "### Data preparation (9 marks)\n",
    "\n",
    "- Print the first image in the train image and figure out the shape of the images (1 mark)\n",
    "- Reshape the train and the test dataset to flatten them. Figure out the required shape (3 marks)\n",
    "- Normalise the train and the test dataset by dividing by 255. (2 mark)\n",
    "- Print the new shapes of the train and the test set. (1 mark)\n",
    "- One hot encode the target variables (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqndzQXng9rL"
   },
   "outputs": [],
   "source": [
    "# Shape of the images and the first image\n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "# print(\"Shape:\", X_train[0]._____)\n",
    "# print()\n",
    "# print(\"First image:\\n\", ______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9YPwf9ysqWU"
   },
   "outputs": [],
   "source": [
    "# Reshaping the dataset to flatten them. Remember that we are trying to reshape the 2D image data into a 1D array\n",
    "# Uncomment below and fill in the blanks\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[_], ____)\n",
    "# X_test = X_test.reshape(X_test.shape[_], ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_yUUTp_mUzB"
   },
   "outputs": [],
   "source": [
    "# Normalize inputs from 0-255 to 0-1\n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "# X_train = _________\n",
    "# X_test = _________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1606902344017,
     "user": {
      "displayName": "Shrish Chandra Pandey",
      "photoUrl": "",
      "userId": "03777729159992968707"
     },
     "user_tz": -330
    },
    "id": "t7FSqOpamWkH",
    "outputId": "794b628a-0c95-436b-d1bd-32d9f445618f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (42000, 1024) (42000,)\n",
      "Test set: (18000, 1024) (18000,)\n"
     ]
    }
   ],
   "source": [
    "# New shape \n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "\n",
    "# print('Training set:', __________, ___________)\n",
    "# print('Test set:', __________, ________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL0lYER4sqWw"
   },
   "outputs": [],
   "source": [
    "# one hot encode output\n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "# y_train = _____________(y_train1)\n",
    "# y_test = _____________(y_test1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJDUoaEj1d6e"
   },
   "source": [
    "### Model Building (13 marks)\n",
    "- Write a function that returns a sequential model with the following architecture\n",
    " - First hidden layer with 256 nodes and relu activation\n",
    " - Second hidden layer with 64 nodes and relu activation \n",
    " - Third hidden layer with 64 nodes and relu activation\n",
    " - 4th hidden layer with 32 nodes and relu activation\n",
    " - Output layer with softmax activation and no of nodes equal to the number of classes\n",
    "- Compile the model with the categorical_crossentropy loss, adam optmizers (lr = 0.001) and accuracy metric\n",
    "- do not fit the model here, just return the compiled model\n",
    "- Call the model and fit on the train data with a validation split of 0.2, batch size = 128, verbose = 1 and 30 epochs. Store the model building history to use it later for visualisation.\n",
    "- print the summary of the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmi81Gr5sqW-"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "def nn_model_1():\n",
    "    # create model\n",
    "    model = Sequential()  \n",
    "    #add layers as per instructions above\n",
    "    # Your code here\n",
    "    # Compile model\n",
    "    # adam = _______.Adam(lr=1e-3)\n",
    "    # model.compile(loss=______________, optimizer=____, _________=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGCUI_xsImnH"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "# Call function here\n",
    "# model_1 = ________()\n",
    "\n",
    "# Fit the model and store the history\n",
    "# history_model_1 = model_1.fit(_______________________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckJsLdmdQadZ"
   },
   "outputs": [],
   "source": [
    "#model summary here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKOckG-KPyLg"
   },
   "source": [
    "### Plotting the validation and training accuracies (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt77zgGMP4yw"
   },
   "outputs": [],
   "source": [
    "# plotting the accuracies\n",
    "# Uncomment and fill in the blanks\n",
    "\n",
    "\n",
    "# dict_hist = history_model_1.________\n",
    "# list_ep = [i for i in range(1,31)]\n",
    "\n",
    "# plt.figure(figsize = (8,8))\n",
    "# plt.plot(___________________)\n",
    "# plt.plot(___________________)\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGBbQpLONX7k"
   },
   "source": [
    "**Comments**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kuXx9Bvu00f"
   },
   "source": [
    "### Test set prediction and final comments (3 marks)\n",
    "- predict on the test set and comment on the resultls obtained. (3 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRddeJ-3EHT1"
   },
   "outputs": [],
   "source": [
    "# Uncomment and fill in the blanks\n",
    "\n",
    "# predict on the test dataset\n",
    "# test_pred = _________________\n",
    "\n",
    "#Print the classificatio report\n",
    "from sklearn.metrics import classification_report\n",
    "# print(____________________(y_test1, test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjErl4GA2u9s"
   },
   "source": [
    "#### Comments:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETAFZO9oFkdA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "8lsux2ZwyTTR"
   ],
   "name": "Project NN: SVHN Project - Learners Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
